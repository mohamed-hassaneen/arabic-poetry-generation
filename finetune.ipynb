{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7q6D2AwxWcs"
   },
   "source": [
    "# 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M7nmJjsWvvex",
    "outputId": "3cfa19b0-0977-46bb-f9ba-6190a0e70ff2"
   },
   "outputs": [],
   "source": [
    "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\" --quiet\n",
    "!pip install --no-deps xformers \"trl<0.9.0\" peft accelerate bitsandbytes --quiet\n",
    "!pip install rich --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9f-XDOEh6NI"
   },
   "source": [
    "# 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g0-GDSDZiAVC",
    "outputId": "e4f3e985-c24e-4778-9a15-4c1af44ddf66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "GPU Detected: NVIDIA H200 MIG 1g.18gb\n",
      "Total VRAM: 16.0 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "# Verification\n",
    "assert torch.cuda.is_available(), \"GPU is not detected!\"\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "print(f\"GPU Detected: {gpu_stats.name}\")\n",
    "print(f\"Total VRAM: {round(gpu_stats.total_memory / 1024**3, 2)} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WOZKLY7i_Zd"
   },
   "source": [
    "# 3. Model & Tokenizer Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7u3g-oePjBIn",
    "outputId": "3661bd39-e80a-43bc-d4c2-7c8e270f1534"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "==((====))==  Unsloth 2026.2.1: Fast Gemma3 patching. Transformers: 4.57.6.\n",
      "   \\\\   /|    NVIDIA H200 MIG 1g.18gb. Num GPUs = 2. Max memory: 16.0 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.10.0+cu128. CUDA: 9.0. CUDA Toolkit: 12.8. Triton: 3.6.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.35. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 512\n",
    "load_in_4bit = True\n",
    "\n",
    "print(\"Loading model...\")\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"google/gemma-3-4b-pt\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = None,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")\n",
    "\n",
    "# Verification\n",
    "assert model is not None and tokenizer is not None, \"Model or tokenizer failed to load.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIJdqv4DrCpI"
   },
   "source": [
    "# 5. LoRA Adapter Injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P_YvqgvOrMsZ",
    "outputId": "4056e239-b0af-43c5-9bc4-2465cadf5a2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Making `base_model.model.model.vision_tower.vision_model` require gradients\n",
      "LoRA Adapters injected successfully. Parameter breakdown:\n",
      "trainable params: 131,153,920 || all params: 4,431,233,392 || trainable%: 2.9598\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 64,\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\"\n",
    "    ],\n",
    "    lora_alpha = 64,\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    ")\n",
    "\n",
    "print(\"LoRA Adapters injected successfully. Parameter breakdown:\")\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_pDIErLrndf"
   },
   "source": [
    "# 6. Dataset Loading & Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rx8gHnZ4sAqb",
    "outputId": "ea6c336f-03de-4709-b1ff-8112bdba4d2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully located dataset files.\n",
      "Dataset formatted. Here is the exact string the model will train on:\n",
      "--------------------------------------------------\n",
      "ÿ£ŸÑŸÖ ÿ™ŸÑŸÖŸÖ ÿπŸÑŸâ ÿßŸÑÿ∑ŸÑŸÑ ÿßŸÑŸÖÿ≠ŸäŸÑ (ÿßŸÑŸàÿßŸÅÿ±) ÿ®ÿ∫ÿ±ÿ®Ÿä ÿßŸÑÿ£ÿ®ÿßÿ±ŸÇ ŸÖŸÜ ÿ≠ŸÇŸäŸÑ (ŸÑ) ÿµÿ±ŸÅÿ™ ÿ®ÿµÿßÿ≠ÿ®Ÿä ÿ∑ÿ±ÿ®ÿß ÿ•ŸÑŸäŸáÿß (ÿßŸÑŸàÿßŸÅÿ±) ŸàŸÖÿß ÿ∑ÿ±ÿ® ÿßŸÑÿ≠ŸÑŸäŸÖ ÿ•ŸÑŸâ ÿßŸÑÿ∑ŸÑŸàŸÑ (ŸÑ) ŸÅŸÑŸÖ ÿ£ÿ± ÿ∫Ÿäÿ± ÿ¢ŸÜÿßÿ° ÿ£ÿ≠ÿßÿ∑ÿ™ (ÿßŸÑŸàÿßŸÅÿ±) ÿπŸÑŸâ ÿßŸÑÿπÿ±ÿµÿßÿ™ ŸÖŸÜ ÿ≠ÿ∞ÿ± ÿßŸÑÿ≥ŸäŸàŸÑ (ŸÑ) ÿ™ŸÜÿ≥ŸÅŸáÿß ÿßŸÑÿ®Ÿàÿßÿ±ÿ≠ ŸÅŸáŸä ÿØŸÅ (ÿßŸÑŸàÿßŸÅÿ±) ÿ£ÿ¥ŸÑ ŸàÿØŸÅ ŸÖÿÆÿ™ÿ¥ÿπ ÿ∞ŸÑŸàŸÑ (ŸÑ) Ÿàÿ±ÿ≥ŸÖ ŸÖÿ®ÿßÿ°ÿ© Ÿàÿ±ŸÖÿßÿØ ŸÜÿßÿ± (ÿßŸÑŸàÿßŸÅÿ±) Ÿàÿ¨ŸàŸÜ ÿ≠ŸàŸÑ ŸÖŸàŸÇÿØŸáÿß ŸÖÿ´ŸàŸÑ (ŸÑ) ÿØŸäÿßÿ± ŸÖŸÜ ÿ£ŸÖÿßŸÖÿ© ÿ•ÿ∞ ÿ±ŸÖÿ™ŸÜÿß (ÿßŸÑŸàÿßŸÅÿ±) ÿ®ÿ≥ŸáŸÖ ŸÅŸä ŸÖÿ®ÿßÿπÿØÿ© ŸÇÿ™ŸàŸÑ (ŸÑ) ÿ±ŸÖŸäÿ™ ÿ®ŸÖŸÇŸÑÿ™ŸäŸÉ ÿßŸÑŸÇŸÑÿ® ÿ≠ÿ™Ÿâ (ÿßŸÑŸàÿßŸÅÿ±) ÿ£ÿµÿ®ÿ™ ÿßŸÑŸÇŸÑÿ® ÿ®ÿßŸÑÿ´ŸÇŸÑ ÿßŸÑŸÉŸÑŸäŸÑ (ŸÑ) ŸÅŸÑŸÖÿß ÿ£ŸÜ ŸÜÿ≤ŸÑÿ™ ÿ¥ÿπÿßÿ® ŸÇŸÑÿ®Ÿä (ÿßŸÑŸàÿßŸÅÿ±) ŸÖÿØÿØÿ™ ŸÑŸÜÿß ŸÖÿ®ÿßÿπÿØÿ© ÿßŸÑÿ®ÿÆŸäŸÑ (ŸÑ) ÿ≥ŸÖÿπÿ™ ŸÖŸÇÿßŸÑÿ© ÿßŸÑŸàÿßÿ¥ŸäŸÜ ÿ≠ÿ™Ÿâ (ÿßŸÑŸàÿßŸÅÿ±) ŸÇÿ∑ÿπÿ™ ÿ≠ÿ®ÿßŸÑ ÿµÿ±ÿßŸÖ ŸàÿµŸàŸÑ (ŸÑ) ÿ•ÿ∞ÿß ÿ∞ŸáŸÑ ÿßŸÑŸÖÿ®ÿßÿπÿØ ÿπŸÜ ŸàÿµÿßŸÑ (ÿßŸÑŸàÿßŸÅÿ±) ŸÑÿ¨ÿ¨ŸÜÿß ŸÅŸä ÿßŸÑÿ™ÿ®ÿßÿπÿØ ŸàÿßŸÑÿ∞ŸáŸàŸÑ (ŸÑ) ŸÖÿØÿØÿ™ ÿ®ÿ≠ÿ®ŸÑŸáÿß ÿ≤ŸÖŸÜÿß ŸÅÿ£ŸÖÿ≥ÿ™ (ÿßŸÑŸàÿßŸÅÿ±) ÿ≠ÿ®ÿßŸÑ ÿßŸÑŸàÿµŸÑ ÿ¨ÿßÿ∞ŸÖÿ© ÿßŸÑŸàÿ≥ŸäŸÑ (ŸÑ) ŸÉÿ£ŸÜ ÿßŸÑÿ≠ÿ®ŸÑ ŸÑŸÖ ŸäŸàÿµŸÑ ÿ™ŸÖÿßŸÖÿß (ÿßŸÑŸàÿßŸÅÿ±) ÿ•ÿ∞ÿß ÿ£ŸÜŸÇÿ∑ÿπ ÿßŸÑÿÆŸÑŸäŸÑ ŸÖŸÜ ÿßŸÑÿÆŸÑŸäŸÑ (ŸÑ) ŸÅÿÆÿ±ÿ™ ÿßÿ®ŸÜ ÿßŸÑÿ£ÿ™ÿßŸÜ ÿ®ÿ®Ÿäÿ™ ŸÑÿ§ŸÖ (ÿßŸÑŸàÿßŸÅÿ±) ŸàŸÖÿß ŸÑŸÉ ŸÅŸä ÿßŸÑÿ£ŸÉÿßÿ±ŸÖ ŸÖŸÜ ŸÇÿ®ŸäŸÑ (ŸÑ) ŸàŸÑŸÖ ŸäŸÉ ÿ¨ÿØŸÉ ÿßŸÑÿÆÿ∑ŸÅŸâ ŸÅÿ≠ŸäŸÑÿß (ÿßŸÑŸàÿßŸÅÿ±) ŸÅÿ™ÿ≠ŸÖÿØŸá ŸàŸÑÿß ÿ´ÿßŸÜŸä ÿßŸÑŸÅÿ≠ŸäŸÑ (ŸÑ) ŸÉŸÑŸäÿ® ÿ•ŸÜ ÿπÿØÿØÿ™ ÿ®ŸÜŸä ŸÉŸÑŸäÿ® (ÿßŸÑŸàÿßŸÅÿ±) ÿ¨ÿ≠ÿßÿ¥ ÿßŸÑŸÑÿ§ŸÖ ŸÅŸä ÿßŸÑÿπÿØÿØ ÿßŸÑŸÇŸÑŸäŸÑ (ŸÑ) ŸàŸÑŸÖ ÿ™ÿπÿ±ŸÅ ŸÉŸÑŸäÿ® ÿßŸÑŸÑÿ§ŸÖ ÿ•ŸÑÿß (ÿßŸÑŸàÿßŸÅÿ±) ÿ®ÿ¥ÿßÿ±ŸÅŸáÿß Ÿàÿ®ÿßÿ¶ÿ≥Ÿáÿß ÿßŸÑÿ≥ÿ§ŸàŸÑ (ŸÑ) ŸàŸÖÿß ŸÉÿßŸÜÿ™ ÿ®ŸäŸàÿ™ ÿ®ŸÜŸä ŸÉŸÑŸäÿ® (ÿßŸÑŸàÿßŸÅÿ±) ÿ™ÿ≠ŸÑ ÿßŸÑÿ∫Ÿäÿ´ ÿ•ŸÑÿß ÿ®ÿßŸÑŸÉŸÅŸäŸÑ (ŸÑ) ŸÉŸÑŸäÿ® ŸÖŸÜŸäÿ© ÿßŸÑÿ∫ÿßÿ≤Ÿä ÿ•ÿ∞ÿß ŸÖÿß (ÿßŸÑŸàÿßŸÅÿ±) ÿ∫ÿ≤ÿß ÿ£Ÿà ÿ¥ŸÇŸàÿ© ÿßŸÑÿ∂ŸäŸÅ ÿßŸÑÿØÿÆŸäŸÑ (ŸÑ) ŸÅÿ•ŸÜŸÉ ŸÇÿØ Ÿàÿ¨ÿØÿ™ ÿ®ŸÜŸä ŸÉŸÑŸäÿ® (ÿßŸÑŸàÿßŸÅÿ±) ŸÇÿµÿßÿ± ÿßŸÑŸÅÿ±ÿπ ÿ®ÿßŸÑŸäÿ© ÿßŸÑÿ£ÿµŸàŸÑ (ŸÑ) ŸÅÿÆÿ±ÿ™ ÿ®ŸÖÿß ÿ®ŸÜÿ™ ŸÅÿ±ÿ≥ÿßŸÜ ÿ™ŸäŸÖ (ÿßŸÑŸàÿßŸÅÿ±) ŸàŸÖÿß ÿ£ÿÆÿ∞Ÿàÿß ÿßŸÑŸÖÿπÿßŸÇŸÑ ŸÖŸÜ ŸÇÿ™ŸäŸÑ (ŸÑ) ÿ£ÿ®ŸàŸÜÿß ÿßŸÑÿ™ŸäŸÖ ÿ£ŸÉÿ±ŸÖ ŸÖŸÜ ÿ£ÿ®ŸäŸÉŸÖ (ÿßŸÑŸàÿßŸÅÿ±) Ÿàÿ£ŸÇÿ±ÿ® ŸÑŸÑÿÆŸÑÿßŸÅÿ© ŸàÿßŸÑÿ±ÿ≥ŸàŸÑ (ŸÑ) Ÿàÿ™ŸäŸÖ ŸÖŸÜŸÉ ÿ£Ÿàÿ™ÿ± ŸÑŸÑÿ£ÿπÿßÿØŸä (ÿßŸÑŸàÿßŸÅÿ±) Ÿàÿ£ÿØÿ±ŸÉ ÿ≠ŸäŸÜ ÿ™ÿ∑ŸÑÿ® ÿ®ÿßŸÑÿ™ÿ®ŸàŸÑ (ŸÑ) ŸàÿÆŸäÿ± ŸÑŸäŸÑÿ© ÿßŸÑÿ≠ÿØÿ´ÿßŸÜ ŸÖŸÜŸÉŸÖ (ÿßŸÑŸàÿßŸÅÿ±) Ÿàÿ£ÿ≥ŸÖÿ≠ ŸÑŸäŸÑÿ© ÿßŸÑÿ±Ÿäÿ≠ ÿßŸÑÿ®ŸÑŸäŸÑ (ŸÑ) Ÿàÿ®ÿßŸÑŸàÿØÿßÿ° ŸäŸàŸÖ ÿ∫ÿ≤Ÿàÿ™ ÿ™ŸäŸÖÿß (ÿßŸÑŸàÿßŸÅÿ±) ÿ≥ŸÇŸàŸÉ ÿ®ŸÖÿ¥ÿ±ÿ® ÿßŸÑŸÉÿØÿ± ÿßŸÑŸàÿ®ŸäŸÑ (ŸÑ) Ÿàÿ™ŸäŸÖ ÿ£ÿ∏ÿπŸÜÿ™ŸÉ ŸÅŸÑŸÖ ÿ™ÿÆŸÑŸÅ (ÿßŸÑŸàÿßŸÅÿ±) Ÿàÿ™ŸäŸÖ ÿ£ÿ¥ÿÆÿµÿ™ŸÉ ÿπŸÜ ÿßŸÑÿ≠ŸÑŸàŸÑ (ŸÑ) Ÿàÿ™ŸäŸÖ Ÿàÿ¨Ÿáÿ™ŸÉ ŸÑŸÉŸÑ ÿ£ŸÖÿ± (ÿßŸÑŸàÿßŸÅÿ±) ÿ™ÿ≠ÿßŸàŸÑŸá ŸàŸÑÿ≥ÿ™ ÿ®ÿ∞Ÿä ÿ≠ŸàŸäŸÑ (ŸÑ) ÿ®ÿ£ÿ®ÿ±ŸÇ ÿ∞Ÿä ÿßŸÑÿ¨ŸÖŸàÿπ ÿ∫ÿØÿßÿ© ÿ™ŸäŸÖ (ÿßŸÑŸàÿßŸÅÿ±) ÿ™ŸÇŸàÿØŸÉ ÿ®ÿßŸÑÿÆÿ¥ÿßÿ¥ÿ© ŸàÿßŸÑÿ¨ÿØŸäŸÑ (ŸÑ) ŸÅÿ£ÿπÿ∑Ÿäÿ™ ÿßŸÑŸÖŸÇÿßÿØÿ© Ÿàÿßÿ≠ÿ™ŸÖŸÑŸÜÿß (ÿßŸÑŸàÿßŸÅÿ±) ÿπŸÑŸâ ÿ£ÿ´ÿ± ÿßŸÑŸÜŸÉŸäÿ´ÿ© ŸàÿßŸÑÿÆŸÖŸàŸÑ (ŸÑ) ÿ≤ŸÖŸäŸÑ Ÿäÿ™ÿ®ÿπ ÿßŸÑÿ£ÿ≥ŸÑÿßŸÅ ŸÖŸÜÿß (ÿßŸÑŸàÿßŸÅÿ±) ŸàŸÖÿß ÿßŸÑÿ≥ŸÑŸÅ ÿßŸÑŸÖŸÇÿØŸÖ ŸÉÿßŸÑÿ≤ŸÖŸäŸÑ (ŸÑ) ŸÅŸÑŸÖÿß ÿ£ŸÜ ŸÑŸÇŸàÿß ÿ±ÿ§ÿ≥ÿßÿ° ÿ≥ÿßÿ±ÿ™ (ÿßŸÑŸàÿßŸÅÿ±) ÿ®ŸÖÿ∞ÿ≠ÿ¨ ŸäŸàŸÖ ÿ™ŸäŸÖÿß ŸàÿßŸÑÿ¥ŸÑŸäŸÑ (ŸÑ) ŸÜÿ≤ŸÑŸÜÿß ŸÑŸÑŸÉÿ™ÿßÿ¶ÿ® ÿ≠ŸäŸÜ ÿØÿßÿ±ÿ™ (ÿßŸÑŸàÿßŸÅÿ±) ŸàŸÇÿØ ÿ±ÿπÿ¥ ÿßŸÑÿ¨ÿ®ÿßŸÜ ÿπŸÜ ÿßŸÑŸÜÿ≤ŸàŸÑ (ŸÑ) ŸÖÿ≥ŸáŸÑÿ© ŸÜŸàÿßŸÅÿ∞Ÿáÿß Ÿàÿ∂ÿ±ÿ® (ÿßŸÑŸàÿßŸÅÿ±) ŸÉÿ£ŸÅŸàÿßŸá ÿßŸÑŸÖŸÇÿ±ÿ≠ÿ© ÿßŸÑŸáÿØŸàŸÑ (ŸÑ) ŸÅÿ±ŸàŸäŸÜÿß ÿ®ŸÖÿ¨ ÿßŸÑŸáÿßŸÖ ŸÖŸÜŸáŸÖ (ÿßŸÑŸàÿßŸÅÿ±) ŸÖÿ∂ÿßÿ±ÿ® ŸÉŸÑ ÿ∞Ÿä ÿ≥ŸäŸÅ ÿµŸÇŸäŸÑ (ŸÑ) ŸÅÿ£ŸÖÿ≥ÿ™ ŸÅŸäŸáŸÖ ÿßŸÑŸÇÿ™ŸÑŸâ ŸÉÿÆÿ¥ÿ® (ÿßŸÑŸàÿßŸÅÿ±) ŸÜŸÅÿßŸáÿß ÿßŸÑÿ≥ŸäŸÑ ÿπŸÜ ÿØÿ±ÿ¨ ÿßŸÑŸÖÿ≥ŸäŸÑ (ŸÑ) ŸàÿÆÿ®ÿ± ÿπŸÜ ŸÖÿµÿßÿ±ÿπ ŸÖŸÜ ŸÇÿ™ŸÑŸÜÿß (ÿßŸÑŸàÿßŸÅÿ±) ŸÅŸÑŸàŸÑ ÿßŸÑÿ¨Ÿäÿ¥ ÿ¥ÿßÿ® ÿ•ŸÑŸâ ÿßŸÑŸÉŸÑŸàŸÑ (ŸÑ) ŸàŸäŸàŸÖ ÿ≥ŸäŸàŸÅŸÉŸÖ ÿÆÿ≤Ÿä ÿπŸÑŸäŸÉŸÖ (ÿßŸÑŸàÿßŸÅÿ±) ÿ•ŸÑŸâ ŸÇŸäÿ≥ ÿßŸÑÿ∞ÿ≠ŸàŸÑ ÿ•ŸÑŸâ ÿßŸÑÿ∞ÿ≠ŸàŸÑ (ŸÑ) ŸàŸäŸàŸÖ ÿ≥ŸäŸàŸÅŸÜÿß ÿ¥ÿ±ŸÇÿß ÿ™ÿ±ŸÇŸâ (ÿßŸÑŸàÿßŸÅÿ±) ŸÖÿπ ÿßŸÑŸÇŸÖÿ±ŸäŸÜ ŸÖŸÜ ÿπÿ∏ŸÖ Ÿàÿ∑ŸàŸÑ (ŸÑ) ŸÑŸÜÿß ŸäŸàŸÖ ÿßŸÑŸÉŸÑÿßÿ® ŸÅÿ¨Ÿäÿ° ÿ®ŸäŸàŸÖ (ÿßŸÑŸàÿßŸÅÿ±) ÿ•ÿ∞ÿß ÿπÿØ ÿßŸÑŸÅÿπÿßŸÑ ÿ®Ÿá ÿ®ÿØŸäŸÑ (ŸÑ) ŸàŸäŸàŸÖ ÿ®ŸÜŸä ÿßŸÑÿµŸÖŸàÿ™ ÿ±ÿ£ÿ™ ŸÉŸÑÿßÿ® (ÿßŸÑŸàÿßŸÅÿ±) ÿ£ÿ≥Ÿäÿ±ÿß ŸÖŸÜŸáŸÖ ÿ®ŸäŸÜ ÿßŸÑÿ∫ŸÑŸàŸÑ (ŸÑ) ŸàŸäŸàŸÖ Ÿäÿ≤ŸäÿØ ŸÑŸà ÿ£ÿ®ÿµÿ±ÿ™ ÿ™ŸäŸÖÿß (ÿßŸÑŸàÿßŸÅÿ±) ÿ±ÿ£Ÿäÿ™ ŸÅŸàÿßÿ±ÿ≥ ÿßŸÑÿ≠ÿ≥ÿ® ÿßŸÑŸÜÿ®ŸäŸÑ (ŸÑ) ÿ£ÿÆÿ∞ŸÜÿß ÿπÿ±ÿ≥Ÿá ŸÅÿ£ÿµÿßÿ® ÿ≥ŸáŸÖ (ÿßŸÑŸàÿßŸÅÿ±) ÿ¥ŸàŸâ ŸÖŸÜŸá ÿ®ŸÜÿßŸÅÿ∞ÿ© ŸáÿØŸàŸÑ (ŸÑ) ŸàŸäŸàŸÖ ÿ£ÿ∫ÿßÿ± ÿ≠ÿ≥ÿßŸÜ ÿ®ŸÜ ÿπŸàŸÅ (ÿßŸÑŸàÿßŸÅÿ±) ÿµÿ±ÿπŸÜÿßŸá ÿ®ŸÜÿßŸÅÿ∞ÿ© ÿ´ÿπŸàŸÑ (ŸÑ) ŸàŸäŸàŸÖ ÿ≥ŸÖÿß ŸÑŸÜÿ≥Ÿàÿ™ŸÜÿß ÿ¥ŸÖŸäÿ∑ (ÿßŸÑŸàÿßŸÅÿ±) ÿ®ŸÖŸÇŸÜÿ®Ÿá ÿπŸÑŸâ ÿ£ÿ´ÿ± ÿßŸÑÿØŸÑŸäŸÑ (ŸÑ) ÿ∫ÿ≤ÿß ÿ®ÿÆŸÖŸäÿ≥Ÿá ŸÖŸÜ ÿ∞ÿßÿ™ ŸÉŸáŸÅ (ÿßŸÑŸàÿßŸÅÿ±) ŸÅŸÇÿ∑ÿ±Ÿá ŸÅŸàÿßÿ±ÿ≥ ÿ∫Ÿäÿ± ŸÖŸäŸÑ (ŸÑ) ŸÑŸäÿßŸÑŸä Ÿäÿπÿ™ÿ≤ŸàŸÜ ÿ•ŸÑŸâ ŸÉŸÑŸäÿ® (ÿßŸÑŸàÿßŸÅÿ±) ÿ®ŸÖÿ¨ÿ™ŸÖÿπ ÿßŸÑÿ¥ŸÇŸäŸÇÿ© ŸàÿßŸÑÿ£ŸÖŸäŸÑ (ŸÑ) ŸÖÿ™Ÿâ ÿ¥ŸáÿØÿ™ ŸÅŸàÿßÿ±ÿ≥ŸÜÿß ŸÉŸÑŸäÿ® (ÿßŸÑŸàÿßŸÅÿ±) ÿ∂ŸÑŸÑÿ™ Ÿàÿ£ŸÜÿ™ ŸÖŸÜ ÿ®ŸÑÿØ ÿßŸÑÿ∂ŸÑŸàŸÑ (ŸÑ) ŸÑŸÜÿß ÿπÿ≤ ÿßŸÑÿ±ÿ®ÿßÿ® Ÿàÿ¢ŸÑ ÿ≥ÿπÿØ (ÿßŸÑŸàÿßŸÅÿ±) ÿπÿ∑ÿßÿ° ÿßŸÑŸàÿßÿ≠ÿØ ÿßŸÑÿµŸÖÿØ ÿßŸÑÿ¨ŸÑŸäŸÑ (ŸÑ) ŸáŸÖ Ÿàÿ∑ÿ¶Ÿàÿß ÿ≠ŸÖÿßŸÉ ŸàŸáŸÖ ÿ£ÿ≠ŸÑŸàÿß (ÿßŸÑŸàÿßŸÅÿ±) ÿ®ŸäŸàÿ™ŸÉŸÖ ÿ®ŸÖŸÜÿ≤ŸÑÿ© ÿßŸÑÿ∞ŸÑŸäŸÑ (ŸÑ) ŸáŸÖ ÿßÿÆÿ™ÿßÿ±Ÿàÿß ÿπŸÑŸäŸÉ ÿ∫ÿØÿßÿ© ÿ≠ŸÑŸàÿß (ÿßŸÑŸàÿßŸÅÿ±) Ÿàÿ®Ÿäÿ™ ÿßÿ®ŸÜ ÿßŸÑŸÖÿ±ÿßÿ∫ÿ© ÿ®ÿßŸÑŸÖÿ≥ŸäŸÑ (ŸÑ) ÿ≥ÿØÿØÿ™ ÿπŸÑŸäŸÉ ŸÖÿ∑ŸÑÿπ ŸÉŸÑ ÿÆŸäÿ± (ÿßŸÑŸàÿßŸÅÿ±) ŸÅÿπŸä ÿπŸÑŸäŸÉ ŸÖÿ∑ŸÑÿπ ÿßŸÑÿ≥ÿ®ŸäŸÑ (ŸÑ) ÿ±ŸÖÿßŸÉ ÿßŸÑŸÑÿ§ŸÖ ŸÑÿ§ŸÖ ÿ®ŸÜŸä ŸÉŸÑŸäÿ® (ÿßŸÑŸàÿßŸÅÿ±) ÿ®ÿπÿ®ÿ° ŸÑÿß ÿ™ŸÇŸàŸÖ ŸÑŸá ÿ®ŸÇŸäŸÑ (ŸÑ) ÿ£Ÿáÿ® Ÿäÿß ÿ®ŸÜ ÿßŸÑŸÖÿ±ÿßÿ∫ÿ© ŸÖŸÜ ŸÉŸÑŸäÿ® (ÿßŸÑŸàÿßŸÅÿ±) ÿ®ŸÑÿ§ŸÖ ŸÑŸÜ ÿ™ÿ∫Ÿäÿ±Ÿá ÿ∑ŸàŸäŸÑ (ŸÑ) ŸÅŸÇÿØ ÿÆŸÑŸÇÿ™ ŸÉŸÑŸäÿ®ŸÉ ŸÖŸÜ ÿ™ŸÖŸäŸÖ (ÿßŸÑŸàÿßŸÅÿ±) ŸÖŸÉÿßŸÜ ÿßŸÑŸÇÿ±ÿØ ŸÖŸÜ ÿ∞ŸÜÿ® ÿßŸÑŸÅÿµŸäŸÑ (ŸÑ) Ÿàÿ≠ÿ∏ ÿßÿ®ŸÜ ÿßŸÑŸÖÿ±ÿßÿ∫ÿ© ŸÖŸÜ ÿ™ŸÖŸäŸÖ (ÿßŸÑŸàÿßŸÅÿ±) ŸÉÿ≠ÿ∏ ÿßŸÑÿ≤ÿßŸÜŸäÿßÿ™ ŸÖŸÜ ÿßŸÑŸÅÿ≠ŸàŸÑ (ŸÑ) ŸÅÿ•ŸÜŸÉ ŸàÿßŸÅÿ™ÿÆÿßÿ±ŸÉ ŸÖŸÜ ŸÉŸÑŸäÿ® (ÿßŸÑŸàÿßŸÅÿ±) ÿ®ÿ®Ÿäÿ™ ÿßŸÑŸÑÿ§ŸÖ ŸàÿßŸÑÿπÿØÿØ ÿßŸÑŸÇŸÑŸäŸÑ (ŸÑ) ŸÉÿ£Ÿàÿ±ŸÇ ÿ∞ŸÑ ŸÑŸäÿ≥ ŸÑŸá ÿ¨ŸÜÿßÿ≠ (ÿßŸÑŸàÿßŸÅÿ±) ÿπŸÑŸâ ÿπŸàÿØŸäŸÜ ŸäŸÑÿπÿ® ÿ®ÿßŸÑŸáÿØŸäŸÑ (ŸÑ) ŸàŸÇÿØ ÿ±ŸÉÿ®ÿ™ ŸÑÿ∫ÿßŸäÿ™Ÿáÿß ŸÉŸÑŸäÿ® (ÿßŸÑŸàÿßŸÅÿ±) ÿ®ÿ£ÿØŸÅŸâ ÿ≠ŸäŸÜ ÿ™ŸÜÿÆÿ≥Ÿá ÿ≤ÿ≠ŸàŸÑ (ŸÑ) ÿ®Ÿá ÿ≤Ÿàÿ± ÿßŸÑÿπÿ®ŸàÿØÿ© ŸÅŸáŸà ÿ£ÿØŸÜŸâ (ÿßŸÑŸàÿßŸÅÿ±) ŸÜÿµÿ™Ÿá ÿßŸÑÿÆŸäŸÑ ÿπŸÜ ŸÖŸäŸÑ ŸÅŸÖŸäŸÑ (ŸÑ) ÿ≤ŸäÿßŸäÿØ ŸÖŸÜ ÿ±ŸÇÿßÿ¥ ŸÖÿπŸÑŸÇÿßÿ™ (ÿßŸÑŸàÿßŸÅÿ±) ŸÉÿ≠Ÿäÿ∂ ÿßŸÑŸÉŸÑÿ® ŸÜÿßŸÇÿµÿ© ÿßŸÑÿπŸÇŸàŸÑ (ŸÑ) ŸÅÿ•ŸÜ ÿ™ÿÆŸÑÿ∑ ÿ≠Ÿäÿßÿ° ŸÖŸÜ ÿµÿ®Ÿäÿ± (ÿßŸÑŸàÿßŸÅÿ±) ÿ®ŸáŸÖ ÿ™ÿ≥ŸÇ ÿßŸÑÿ≥ŸÅÿßŸÑ ÿ•ŸÑŸâ ÿßŸÑÿÆŸÖŸàŸÑ (ŸÑ) ŸàŸÑŸäÿ≥ ÿßÿ®ŸÜ ÿßŸÑŸÖÿ±ÿßÿ∫ÿ© ŸäŸàŸÖ ÿ™ÿ≥ÿ®Ÿâ (ÿßŸÑŸàÿßŸÅÿ±) ŸÜÿ≥ÿßÿ° ÿßÿ®ŸÜ ÿßŸÑŸÖÿ±ÿßÿ∫ÿ© ÿ®ÿßŸÑÿµÿ§ŸàŸÑ (ŸÑ) Ÿàÿ£ŸÑÿ≠ŸÇŸáŸÜ ÿ£ŸÇŸàÿßŸÖ ÿ≥ŸàÿßŸÉŸÖ (ÿßŸÑŸàÿßŸÅÿ±) ŸàÿπŸÜÿØŸÉ ŸÖÿß ÿ£ÿÆÿ∞ŸÜ ŸàŸáŸÜ ÿ≠ŸàŸÑ (ŸÑ) ŸàŸäŸÑŸÖÿπ ÿ®ÿßŸÑÿ≥ŸäŸàŸÅ ÿ®ŸÜŸà ÿ≠ÿ±Ÿäÿµ (ÿßŸÑŸàÿßŸÅÿ±) ŸàŸÑŸÖ Ÿäÿ¥ŸÅŸàÿß ÿ®Ÿáÿß Ÿàÿ∫ÿ± ÿßŸÑÿπŸÑŸäŸÑ (ŸÑ) ÿπŸÑŸàÿ™ŸÉ ŸàÿßŸÜŸáÿ≤ŸÖÿ™ ÿ•ŸÑŸâ ÿ±Ÿäÿßÿ≠ (ÿßŸÑŸàÿßŸÅÿ±) ÿ™ÿπŸàÿ∞ ÿ®Ÿáÿß ŸÖŸÜ ÿßŸÑÿ£ÿ≥ÿØ ÿßŸÑÿ®ÿ≥ŸäŸÑ (ŸÑ) Ÿàÿ∑ÿßÿ≠ ÿßÿ®ŸÜ ÿßŸÑŸÖÿ±ÿßÿ∫ÿ© ÿ•ÿ∞ ÿ™ÿµŸÑŸâ (ÿßŸÑŸàÿßŸÅÿ±) ÿ®ŸÑŸäÿ´ ÿ®ŸäŸÜ ÿ£ŸÜŸáÿßÿ± Ÿàÿ∫ŸäŸÑ (ŸÑ) Ÿáÿ≤ÿ®ÿ± ŸäŸÅÿ±ÿ≥ ÿßŸÑÿ£ŸÇÿ±ÿßŸÜ ŸÅÿ±ÿ≥ÿß (ÿßŸÑŸàÿßŸÅÿ±) ÿ®ÿ£ŸÜŸäÿßÿ® ŸÇÿ±ÿßÿ≥Ÿäÿ© ŸÜÿ≤ŸàŸÑ (ŸÑ) ŸÅÿ£ÿ´ÿ®ÿ™ ŸÅŸä ÿßŸÑÿ∞ÿ§ÿßÿ®ÿ© ŸÖŸÜ ÿ¨ÿ±Ÿäÿ± (ÿßŸÑŸàÿßŸÅÿ±) ÿ≤ÿ¨ÿßÿ¨ÿß ŸÖÿß ÿ™ÿÆÿßŸÅ ŸÖŸÜ ÿßŸÑŸÜÿµŸàŸÑ (ŸÑ) ŸÅÿ£ŸÖÿ≥Ÿâ ŸÅÿ±ÿ¨ ÿßŸÑÿ¥ÿ£ŸÜŸäŸÜ ŸÖŸÜŸá (ÿßŸÑŸàÿßŸÅÿ±) ÿ®ŸÉŸÑ ÿ¥ÿ®ÿßÿ© ÿ∞Ÿä ÿ∑ÿ±ŸÅ ÿ£ÿ≥ŸäŸÑ (ŸÑ) ÿ™ÿ∑ŸÑÿ®Ÿá ÿπÿ∑Ÿäÿ© ŸàŸáŸà ŸÖŸäÿ™ (ÿßŸÑŸàÿßŸÅÿ±) ŸäŸÇÿ∂Ÿä ŸàŸáŸà Ÿäÿ≥ÿ®ÿ± ÿ®ÿßŸÑŸÅÿ™ŸäŸÑ (ŸÑ) ÿ•ÿ∞ÿß ŸÖÿß ÿ∂ŸÖŸáÿß ÿ®ÿßŸÑÿ≥ŸÖŸÜ ÿ¨ÿßÿ¥ÿ™ (ÿßŸÑŸàÿßŸÅÿ±) ÿ®Ÿá ÿ¨Ÿäÿ¥ ÿßŸÑŸÖÿπÿ±ŸÖÿ∂ÿ© ÿßŸÑÿØÿ≠ŸàŸÑ (ŸÑ) ÿ≥ÿ£ÿ¥ÿ™ŸÖŸÉŸÖ Ÿàÿ•ŸÜ ŸÜŸáŸÇÿ™ ŸÉŸÑŸäÿ® (ÿßŸÑŸàÿßŸÅÿ±) ÿµŸáŸÑÿ™ ŸàŸÖÿß ÿßŸÑŸÜŸàÿßŸáŸÇ ŸÉÿßŸÑÿµŸáŸäŸÑ (ŸÑ) ÿ™ŸÖÿ¥Ÿâ ÿ∫Ÿäÿ± ŸÖÿ¥ÿ™ŸÖŸÑ ÿ®ÿ´Ÿàÿ® (ÿßŸÑŸàÿßŸÅÿ±) ÿ≥ŸàŸâ ÿÆŸÑ ÿßŸÑŸÅŸÑŸäÿ¨ÿ© ÿ®ÿßŸÑÿÆŸÑÿßŸÑ (ŸÑ)<eos>\n",
      "--------------------------------------------------\n",
      "Total training examples ready: 55523\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "\n",
    "train_file = \"./train.jsonl\"\n",
    "val_file = \"./val.jsonl\"\n",
    "\n",
    "# Verification 1: File Existence\n",
    "assert os.path.exists(train_file), f\"Could not find train file at {train_file}\"\n",
    "assert os.path.exists(val_file), f\"Could not find val file at {val_file}\"\n",
    "print(\"Successfully located dataset files.\")\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files={\"train\": train_file, \"val\": val_file})\n",
    "\n",
    "text_tokenizer = tokenizer.tokenizer if hasattr(tokenizer, \"tokenizer\") else tokenizer\n",
    "\n",
    "def formatting_func(examples):\n",
    "    texts = []\n",
    "    for poem in examples[\"poem\"]:\n",
    "        clean_poem = poem.replace(\"[\", \"(\").replace(\"]\", \")\") \n",
    "        clean_poem = clean_poem.strip()\n",
    "        text = clean_poem + text_tokenizer.eos_token\n",
    "        texts.append(text)\n",
    "        \n",
    "    return { \"text\" : texts }\n",
    "\n",
    "formatted_dataset = dataset.map(formatting_func, batched = True)\n",
    "\n",
    "# Verification 2: Data Formatting\n",
    "sample_text = formatted_dataset[\"train\"][\"text\"][0]\n",
    "print(\"Dataset formatted. Here is the exact string the model will train on:\")\n",
    "print(\"-\" * 50)\n",
    "print(sample_text)\n",
    "print(\"-\" * 50)\n",
    "assert sample_text.endswith(text_tokenizer.eos_token), \"Missing EOS token at the end of the data!\"\n",
    "\n",
    "full_train_dataset = formatted_dataset[\"train\"].shuffle(seed=42)\n",
    "print(f\"Total training examples ready: {len(full_train_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5QX5BQ64uJn_"
   },
   "source": [
    "# 7. Training Setup and Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171,
     "referenced_widgets": [
      "8aa8fff5dc7e48d09f62ea347b68856c",
      "61db4b2e8f9b4405ace89bc81b32b6c8",
      "40971230aefc4bd4a42b77aef96b6037",
      "83df3db225a248548ec9369becbc8211",
      "717976e2da3242f7a9c7b629ad5491dc",
      "7d80baba8ce143a3a4219df01756da57",
      "22a2a459a446474d8a5c26e5137f8f8e",
      "39df95f2e70e4f1d823a4d1f708b3b89",
      "bbef14e289d845eabec169f2d151ebdc",
      "54f3d1db4de34fa6a61c393e63d134ca",
      "1e0b8f4db79643069bbf8be7ef7c4355"
     ]
    },
    "id": "sJMxrA5iuQON",
    "outputId": "4dca5a7d-d3c0-4352-e940-c56386894764"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 161,065 | Num Epochs = 1 | Total steps = 800\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 8 x 1) = 16\n",
      " \"-____-\"     Trainable parameters = 131,153,920 of 4,431,233,392 (2.96% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='800' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [800/800 54:17, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.750600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.792400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.817100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.769200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.778800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>5.853200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>5.830200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>5.828100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.848900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>5.790700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>5.828500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>5.810700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>5.874600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>5.817300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>5.849400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>5.879600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>5.866700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>5.836200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>5.872800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>5.888600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>5.804800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>5.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>5.859600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>5.876000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>5.848000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>5.855400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>5.892500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>5.932100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>5.919600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>5.899200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>5.914800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>5.906800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>5.939000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>5.866800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>5.913500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>5.896900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>5.961200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>5.933200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>5.869800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>5.956800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>5.894700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>5.947200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>5.933800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>5.928700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>5.942800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>5.980700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>5.871300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>5.946500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>5.909300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>5.951500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>6.007200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>5.985600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>5.923100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>5.905200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>5.909000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>5.939200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>5.947200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>5.986500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>5.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>5.957300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>5.973600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>6.009900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>5.881800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>5.934600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>5.959000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>5.942700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>5.961800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>5.970600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>5.988300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>5.933100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>5.937100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>5.923800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>5.976400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>5.923800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>5.951300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>5.952500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>5.957600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>5.921600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>5.941600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=800, training_loss=5.901845726966858, metrics={'train_runtime': 3261.8684, 'train_samples_per_second': 3.924, 'train_steps_per_second': 0.245, 'total_flos': 7.3831461421056e+16, 'train_loss': 5.901845726966858, 'epoch': 0.07947052760979971})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TORCHDYNAMO_DISABLE\"] = \"1\"\n",
    "os.environ[\"PYTORCH_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "import torch, gc\n",
    "gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "model.config.use_cache = False\n",
    "if hasattr(model.config, \"text_config\"):\n",
    "    model.config.text_config._attn_implementation = \"eager\"\n",
    "else:\n",
    "    model.config._attn_implementation = \"eager\"\n",
    "\n",
    "if getattr(text_tokenizer, \"pad_token\", None) is None:\n",
    "    text_tokenizer.pad_token = text_tokenizer.eos_token\n",
    "\n",
    "FastLanguageModel.for_training(model)\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = text_tokenizer,\n",
    "    train_dataset = full_train_dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = 256,\n",
    "    packing = True,\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 1,\n",
    "        gradient_accumulation_steps = 8, \n",
    "        max_steps = 800,\n",
    "        num_train_epochs = 3,\n",
    "        learning_rate = 2e-5,\n",
    "        lr_scheduler_type = \"cosine\",\n",
    "        max_grad_norm = 0.5,\n",
    "        warmup_steps = 50,\n",
    "        warmup_ratio = 0.1,\n",
    "        fp16 = True,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        logging_steps = 10,\n",
    "        output_dir = \"outputs\",\n",
    "        save_strategy = \"no\",\n",
    "        eval_strategy = \"no\",\n",
    "        torch_compile = False,\n",
    "        report_to = \"none\",\n",
    "        average_tokens_across_devices = False,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\"Starting training....\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPgJGmLT3EIV"
   },
   "source": [
    "# 8. Save the fine-tuned Model Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "tGOOAEWK3KZW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully saved to: ./model/\n"
     ]
    }
   ],
   "source": [
    "save_directory = \"./model/\"\n",
    "\n",
    "# Save the model and the tokenizer\n",
    "model.save_pretrained(save_directory)\n",
    "text_tokenizer.save_pretrained(save_directory)\n",
    "\n",
    "print(f\"Model successfully saved to: {save_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXpZG6lI3eer"
   },
   "source": [
    "# 9. Test Poetry Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "TI_i7MPC3ib0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating verses...\n",
      "\n",
      "==================================================\n",
      "ÿßŸÑÿπŸÑŸÖ ÿ≤ŸäŸÜ Ÿàÿ™ÿ¥ÿ±ŸäŸÅ ŸÑÿµÿßÿ≠ÿ®Ÿá (ÿßŸÑÿ∑ŸÑŸÅ) ŸÅŸÑŸá ÿ£ÿ®ÿßÿ®ŸÉ ŸàŸÉŸÖ ÿ∞ŸÑŸáŸÖ ŸÖŸÜ ÿßŸÑÿ≥ŸÇÿßŸÇÿß \n",
      "\n",
      "* ŸÇÿ∑Ÿá ŸÅŸä ÿßŸÑÿ∑ÿßŸÖŸÖ ÿ£Ÿà ÿ∫ÿ∂ÿØŸáÿß ŸÉÿßŸÑŸáŸÖÿß. ŸàŸÇÿØ ŸäŸÅÿ±Ÿâ ÿπŸÑŸâ ÿßŸÑÿ≠ÿ≥ÿ® ŸàÿßŸÑÿÆŸÑŸÇ ŸÖÿß ŸÑÿß ÿ™ÿ±ÿßŸäŸÜ ŸÇŸÖÿπÿ™ ÿßŸÑÿ∞ÿßÿπ ŸàŸÖÿ≠ÿßÿ¶ŸÑ Ÿàÿ£ÿ≥ŸÑÿßÿ≠ÿ©, ŸàŸÑÿß ÿ™ÿ®ÿ¨Ÿàÿß ÿ®Ÿáÿß ÿµÿ±ÿßÿØ Ÿàÿ¨ŸÜÿßŸÜŸä I\" ŸàŸÖŸÜ ŸÑŸÑŸá ŸÑŸá ÿ≤ÿ®ÿßÿ° ÿßŸÑŸÖÿ±ÿ¨ÿßŸÜ Ÿàÿßÿ≤ŸÑŸâ ŸÑŸÜŸäÿ¥ Ÿáÿ∞ÿß ŸÜŸÇŸÑÿ© ÿ®ŸáŸäŸàŸÖ ÿßŸÑÿπÿßÿ±ÿå ŸàŸÉÿ∞ŸÑŸÉ ŸÖŸÑŸÉŸÜÿß ŸÖÿπÿßŸäŸäÿ± ŸÑŸÑÿ¨ÿØ ŸÑŸà ÿ£ŸÜ ÿ£ŸÑŸÅŸäÿßÿ™ ÿßŸÑÿµŸäÿ® ÿ•ŸÑŸâ ÿ£ÿ≠ÿØÿßŸÉŸÜ ÿ•ÿ∞ ÿ∞ÿßŸäÿß ŸÖÿ¨ŸÑÿ© ÿßŸÑŸÅÿßÿ®ÿ±\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "class VerseCountStoppingCriteria(StoppingCriteria):\n",
    "    def __init__(self, rhyme_token_ids, target_verses):\n",
    "        self.rhyme_token_ids = set(rhyme_token_ids)\n",
    "        self.target_verses = target_verses\n",
    "        self.verse_count = 0 \n",
    "\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        last_token = input_ids[0][-1].item()\n",
    "        if last_token in self.rhyme_token_ids:\n",
    "            self.verse_count += 1\n",
    "        return self.verse_count >= self.target_verses\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "prompt_text = \"ÿßŸÑÿπŸÑŸÖ ÿ≤ŸäŸÜ Ÿàÿ™ÿ¥ÿ±ŸäŸÅ ŸÑÿµÿßÿ≠ÿ®Ÿá (\" \n",
    "N_verses = 3\n",
    "\n",
    "inputs = text_tokenizer(prompt_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "rhyme_tags = [\"(ÿ°)\", \"(ÿß)\", \"(ÿ®)\", \"(ÿ™)\", \"(ÿ´)\", \"(ÿ¨)\", \"(ÿ≠)\", \"(ÿÆ)\", \"(ÿØ)\", \"(ÿ∞)\",\n",
    "              \"(ÿ±)\", \"(ÿ≤)\", \"(ÿ≥)\", \"(ÿ¥)\", \"(ÿµ)\", \"(ÿ∂)\", \"(ÿ∑)\", \"(ÿ∏)\", \"(ÿπ)\", \"(ÿ∫)\",\n",
    "              \"(ŸÅ)\", \"(ŸÇ)\", \"(ŸÉ)\", \"(ŸÑ)\", \"(ŸÖ)\", \"(ŸÜ)\", \"(Ÿá)\", \"(Ÿà)\", \"(Ÿä)\"]\n",
    "\n",
    "rhyme_token_ids = []\n",
    "for tag in rhyme_tags:\n",
    "    encoded = text_tokenizer.encode(tag, add_special_tokens=False)\n",
    "    if encoded:\n",
    "        rhyme_token_ids.append(encoded[-1]) \n",
    "\n",
    "stopper = VerseCountStoppingCriteria(rhyme_token_ids, N_verses)\n",
    "\n",
    "print(f\"Generating verses...\")\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens = 128,\n",
    "    do_sample = True,\n",
    "\n",
    "    temperature = 0.2,\n",
    "    top_p = 0.8,\n",
    "    repetition_penalty = 1.3,\n",
    "    \n",
    "    use_cache = True,\n",
    ")\n",
    "\n",
    "poem = text_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(poem)\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8PEDkRNF6ZlX"
   },
   "source": [
    "# 10. Upload LoRA Adapters to HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "J88kzR-n6fU-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2026.2.1: Fast Gemma3 patching. Transformers: 4.57.6.\n",
      "   \\\\   /|    NVIDIA H200 MIG 1g.18gb. Num GPUs = 2. Max memory: 16.0 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.10.0+cu128. CUDA: 9.0. CUDA Toolkit: 12.8. Triton: 3.6.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.35. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8164ab455c394663a6aa340d66ff8e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed7684b62e4f4ce2af3d8327b8aea7cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "411266c9e4b146cbb7124b0511603456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to https://huggingface.co/mohamed-hassaneen/arabic-poetry-gemma-3-4b\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20e66ae8ab604b819bafdf7c645ac107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c4980dba3e4e059a49ad4769557468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adapters are LIVE! View here: https://huggingface.co/mohamed-hassaneen/arabic-poetry-gemma-3-4b\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "hf_model_id = \"mohamed-hassaneen/arabic-poetry-gemma-3-4b\"\n",
    "local_model_path = \"./model\"\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = local_model_path,\n",
    "    max_seq_length = 256,\n",
    "    dtype = None,\n",
    "    load_in_4bit = True,\n",
    ")\n",
    "\n",
    "model.push_to_hub(hf_model_id, token = \"XXX\")\n",
    "tokenizer.push_to_hub(hf_model_id, token = \"XXX\")\n",
    "\n",
    "print(f\"Adapters are LIVE! View here: https://huggingface.co/{hf_model_id}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1e0b8f4db79643069bbf8be7ef7c4355": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "22a2a459a446474d8a5c26e5137f8f8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "39df95f2e70e4f1d823a4d1f708b3b89": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "40971230aefc4bd4a42b77aef96b6037": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39df95f2e70e4f1d823a4d1f708b3b89",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bbef14e289d845eabec169f2d151ebdc",
      "value": 1
     }
    },
    "54f3d1db4de34fa6a61c393e63d134ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61db4b2e8f9b4405ace89bc81b32b6c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d80baba8ce143a3a4219df01756da57",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_22a2a459a446474d8a5c26e5137f8f8e",
      "value": "Generating‚Äátrain‚Äásplit:‚Äá"
     }
    },
    "717976e2da3242f7a9c7b629ad5491dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d80baba8ce143a3a4219df01756da57": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83df3db225a248548ec9369becbc8211": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_54f3d1db4de34fa6a61c393e63d134ca",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_1e0b8f4db79643069bbf8be7ef7c4355",
      "value": "‚Äá1201/0‚Äá[00:02&lt;00:00,‚Äá668.56‚Äáexamples/s]"
     }
    },
    "8aa8fff5dc7e48d09f62ea347b68856c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_61db4b2e8f9b4405ace89bc81b32b6c8",
       "IPY_MODEL_40971230aefc4bd4a42b77aef96b6037",
       "IPY_MODEL_83df3db225a248548ec9369becbc8211"
      ],
      "layout": "IPY_MODEL_717976e2da3242f7a9c7b629ad5491dc"
     }
    },
    "bbef14e289d845eabec169f2d151ebdc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
